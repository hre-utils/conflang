#!/bin/bash

# TODO:
# Quick nifty idea for printing errors in importing/constraint files. We want
# to be able to reference them by name, but ideally we want to use the shortest
# name possible. No sense printing the entire path.
# If we take all of the file names the user has passed, split them on `/` chars,
# and check for uniqueness starting from the end. E.g.,
#> files: [
#>    /home/aurelius/bin/conf
#>    /home/aurelius/bin/do_stuff.sh
#>    /home/marcus/bin/do_stuff.sh
#> ]
#>
#> files[0].split('/')[-1]  is unique
#> files[1].split('/')[-1]  is NOT unique
#>
#> files[1].split('/')[-2:-1]  is unique
#
# I guess realistically we're doing a slice from [N:-1], in which `N = -1`,
# decrementing each time until we find a unique value. We cannot end up with
# non-unique values, as we'll throw a parse error.
#
#
# %include and %constrain directives are handled early in the parser, so it's
# not hitting the tree-walk for semantic checking and whatnot. Need a way of
# enforcing the user does not pass more than 1 constrain, and only does so in
# the '%inline' section. Should throw an error if used anywhere else. Perhaps
# for now also disallow nested %include's.


declare -g PROGDIR=$( cd "$( dirname "${BASH_SOURCE[0]}" )" ; pwd )
declare -g LIBDIR="${PROGDIR}/lib"
declare -g INPUT="$1"

if [[ -z "$INPUT" ]] ; then
   echo "Requires file input" 1>&2
   exit -1
fi

# Shouldn't code file names/paths into the generated output. If the user has the
# same file *data*, but it's in a different place, we shouldn't have to
# re-compile the output.
# An array of files allows us to map a static file INDEX (stored in the output
# data), to the possibly dynamic path to the file.
declare -ga FILES=()

function add_file {
   # Serves to both ensure we don't have circular imports, as well as resolving
   # relative paths to their fully qualified path.
   local -- file=$1

   # The 1st call of `add_file()` will have an empty FILES[] array. This only
   # occurs for the initial file passed in via the CLI. The parent of relative
   # paths is thus the cwd.

   local -- fq_path=
   local -- parent

   if [[ "${#FILES[@]}" -gt 0 ]] ; then
      parent="${FILES[-1]}"
   else
      parent="${BASH_SOURCE[0]}"
   fi

   case "$file" in
      # Absolute paths.
      /*)   fq_path="${file}"             ;;
      ~*)   fq_path="${file/\~/${HOME}}"  ;;

      # Paths relative to the calling file.
      *)    fq_path=$( realpath -m "$(dirname "${parent}")/${file}" -q )
            ;;
   esac

   for f in "${FILES[@]}" ; do
      if [[ "$f" == "$file" ]] ; then
         echo "Cannot source $file, circular import." 1>&2
         # TODO: error reporting
         exit -1
      fi
   done

   FILES+=( "$fq_path" )
}


# This toomfoolery is just to isolate all the functions/variables to each
# respective file. Particularly as the lexer/parser reuse function names like
#  `advance`, `current`, etc.
# Only the particular information we *want* to export is.
function parse {
   source <(
      source <(
         source "${LIBDIR}"/lexer.sh
         # Exports:
         #  TOKENS[]             # Array of token names
         #  TOKEN_$n             # Sequence of all token objects
         #  FILE_LINES[]         # INPUT_FILE.readlines()
      )

      # Since the lexer in run in a subshell (to isolate the name stomping)
      # we need to global these out here.
      declare -p FILE_LINES  FILES |\
         sed -E 's;^declare -(-)?;declare -g;' 

      source "${LIBDIR}"/parser.sh
      # Exports:
      #  ROOT
      #  TYPEOF{}
      #  NODE_*
   )
}


# Parse the top-level `base' file.
add_file "$INPUT"

parse ; root=$ROOT

# Parse all `%include` files.
for insert_node in "${INCLUDES[@]}" ; do
   declare -n node="$insert_node"

   insert_node_to="${node[target]}"
   insert_node_path="${node[path]}"

   add_file "$insert_node_path"

   # File must exist, must be readable.
   if [[ ! -r ${FILES[-1]} ]] ; then
      echo -e "File \`${FILES[-1]}' not readable or doesn't exist."
      continue
   fi

   # Generate AST for the imported file.
   parse
   declare -n child_root="$ROOT"
   declare -n items="${child_root[items]}"

   # Pointer to the location into which the imported nodes will be inserted.
   declare -n insert_node_ptr="$insert_node_to"
   declare -n insert_node_items="${insert_node_ptr[items]}"

   # Append all imported nodes into the intended section.
   for child_node in "${items[@]}" ; do
      insert_node_items+=( "$child_node" )
   done
done

# Restore top-level root node.
ROOT=$root

declare -p ${!NODE_*} | sort -V -k3

# This isn't spectacular error handling, but it does allow us (for now) to halt
# execution if the parser hit an error and exploded.
[[ -z ${!NODE_*} ]] && exit 1

source "${LIBDIR}"/compiler.sh
# Exports (USER ACCESSIBLE):
#  _DATA_ROOT
#  _DATA_*

source "${LIBDIR}"/api.sh
# Exports (USER ACCESSIBLE):
#  RV
#  conf()

# Example usage:
#conf 'key' ; echo "${RV@Q}"
