#!/bin/bash

declare -g PROGDIR=$( cd "$( dirname "${BASH_SOURCE[0]}" )" ; pwd )
declare -g LIBDIR="${PROGDIR}/lib"
declare -g INPUT="$1"

if [[ -z "$INPUT" ]] ; then
   echo "Requires file input" 1>&2
   exit -1
fi

# Shouldn't code file names/paths into the generated output. If the user has the
# same file *data*, but it's in a different place, we shouldn't have to
# re-compile the output.
# An array of files allows us to map a static file INDEX (stored in the output
# data), to the possibly dynamic path to the file.
declare -ga _FILES=( "$INPUT" )
declare -gi _FILE=0
# This -----^ stores the index of the file we're currently looking at. We can
# get the path to the current file with ${_FILES[_FILE]}.

# This toomfoolery is just to isolate all the functions/variables to each
# respective file. Particularly as the lexer/parser reuse function names like
#  `advance`, `current`, etc.
# Only the particular information we *want* to export is.
source <(
   source <( source "${LIBDIR}"/lexer.sh "$INPUT" )
   # Exports:
   #  TOKENS[]             # Array of token names
   #  TOKEN_$n             # Sequence of all token objects
   #  INPUT_FILE           # Name of input file
   #  FILE_LINES[]         # INPUT_FILE.readlines()

   #source "${LIBDIR}"/parser.sh
   source "${LIBDIR}"/parser.sh >&2 && exit
   # Exports:
   #  ROOT
   #  TYPEOF{}
   #  NODE_*
)

# This isn't spectacular error handling, but it does allow us (for now) to halt
# execution if the parser hit an error and exploded.
[[ -z ${!NODE_*} ]] && exit 1

# TODO: Should probably move this up into a subshell, so the user is not also
# sourcing all of our functions and global vars from the compiler. Only the API
# should be inline.
source "${LIBDIR}"/compiler.sh
# Exports (USER ACCESSIBLE):
#  _DATA_ROOT
#  _DATA_*

source "${LIBDIR}"/api.sh
# Exports (USER ACCESSIBLE):
#  RV
#  conf()

# Example usage:
#conf 'global' 'one' ; echo "$RV"
#conf 'key' ; echo "${RV@Q}"
